<template>
  <div class="audio-recorder">
    <!-- å½•åˆ¶æ§åˆ¶é¢æ¿ -->
    <div v-if="showRecordingPanel" 
         class="recording-panel fixed top-20 right-4 bg-base-100 rounded-lg shadow-lg border border-base-300 p-4 z-50"
         style="width: 320px;">
      
      <!-- é¢æ¿æ ‡é¢˜ -->
      <div class="flex items-center justify-between mb-4">
        <h3 class="text-lg font-medium flex items-center gap-2">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 text-primary" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
              d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
          </svg>
          éŸ³é¢‘å½•åˆ¶
        </h3>
        <button @click="closePanel" class="btn btn-ghost btn-sm btn-square">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
          </svg>
        </button>
      </div>

      <!-- è®¾å¤‡å’Œæƒé™çŠ¶æ€æŒ‡ç¤ºå™¨ -->
      <div class="mb-4 p-3 bg-base-200 rounded-lg">
        <div class="flex items-center justify-between text-sm">
          <div class="flex items-center gap-2">
            <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
                d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
            </svg>
            <span>éº¦å…‹é£çŠ¶æ€:</span>
            <button @click="initializeAudioEnvironment" 
                    class="btn btn-ghost btn-xs" 
                    title="åˆ·æ–°çŠ¶æ€æ£€æŸ¥"
                    :disabled="deviceState === 'checking'">
              <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"
                   :class="{ 'animate-spin': deviceState === 'checking' }">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15" />
              </svg>
            </button>
          </div>
          <div class="flex items-center gap-3">
            <!-- è®¾å¤‡çŠ¶æ€ -->
            <div class="flex items-center gap-1">
              <div class="w-2 h-2 rounded-full" 
                   :class="{
                     'bg-success': deviceState === 'available',
                     'bg-error': deviceState === 'unavailable',
                     'bg-warning animate-pulse': deviceState === 'checking'
                   }"></div>
              <span class="text-xs">{{ 
                deviceState === 'available' ? 'è®¾å¤‡å¯ç”¨' : 
                deviceState === 'unavailable' ? 'æ— è®¾å¤‡' : 'æ£€æŸ¥ä¸­...'
              }}</span>
            </div>
            <!-- æƒé™çŠ¶æ€ -->
            <div class="flex items-center gap-1">
              <div class="w-2 h-2 rounded-full" 
                   :class="{
                     'bg-success': permissionState === 'granted',
                     'bg-warning': permissionState === 'prompt',
                     'bg-error': permissionState === 'denied',
                     'bg-gray-400': permissionState === 'unknown'
                   }"></div>
              <span class="text-xs">{{ 
                permissionState === 'granted' ? 'å·²æˆæƒ' : 
                permissionState === 'denied' ? 'æƒé™è¢«æ‹’' : 
                permissionState === 'prompt' ? 'å¾…æˆæƒ' : 'æœªçŸ¥çŠ¶æ€'
              }}</span>
            </div>
          </div>
        </div>
        <!-- æƒé™æç¤º -->
        <div v-if="permissionState === 'denied'" class="mt-2 text-xs text-error">
          <div class="flex items-start gap-1 mb-1">
            <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3 mt-0.5 flex-shrink-0" fill="none" viewBox="0 0 24 24" stroke="currentColor">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-2.5L13.732 4c-.77-.833-1.728-.833-2.498 0L4.316 15.5c-.77.833.192 2.5 1.732 2.5z" />
            </svg>
            <span>éº¦å…‹é£æƒé™è¢«æ‹’ç»</span>
          </div>
          <div class="pl-4 text-xs text-base-content/60">
            è¯·ç‚¹å‡»åœ°å€æ å·¦ä¾§çš„ğŸ”’å›¾æ ‡ï¼Œå…è®¸æ­¤ç½‘ç«™è®¿é—®éº¦å…‹é£ï¼Œç„¶ååˆ·æ–°çŠ¶æ€
          </div>
        </div>
        <div v-else-if="deviceState === 'unavailable'" class="mt-2 text-xs text-warning">
          <div class="flex items-start gap-1 mb-1">
            <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3 mt-0.5 flex-shrink-0" fill="none" viewBox="0 0 24 24" stroke="currentColor">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-2.5L13.732 4c-.77-.833-1.728-.833-2.498 0L4.316 15.5c-.77.833.192 2.5 1.732 2.5z" />
            </svg>
            <span>éº¦å…‹é£è®¾å¤‡æ£€æµ‹</span>
          </div>
          <div class="pl-4 text-xs text-base-content/60 mb-2">
            æ— æ³•æ£€æµ‹åˆ°éº¦å…‹é£è®¾å¤‡ã€‚è¯·ç¡®ä¿ï¼š<br/>
            â€¢ éº¦å…‹é£å·²è¿æ¥å¹¶æ­£å¸¸å·¥ä½œ<br/>
            â€¢ å…¶ä»–åº”ç”¨æ²¡æœ‰å ç”¨éº¦å…‹é£<br/>
            â€¢ å°è¯•ç‚¹å‡»ä¸‹æ–¹"æµ‹è¯•éº¦å…‹é£"æŒ‰é’®
          </div>
                     <button @click="testMicrophone" 
                   :disabled="isLoading"
                   class="btn btn-xs btn-outline btn-warning">
            <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3 mr-1" fill="none" viewBox="0 0 24 24" stroke="currentColor">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
                d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
            </svg>
            æµ‹è¯•éº¦å…‹é£
          </button>
        </div>
        <div v-else-if="permissionState === 'prompt'" class="mt-2 text-xs text-info">
          <div class="flex items-start gap-1 mb-1">
            <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3 mt-0.5 flex-shrink-0" fill="none" viewBox="0 0 24 24" stroke="currentColor">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
            </svg>
            <span>éœ€è¦æˆæƒéº¦å…‹é£æƒé™</span>
          </div>
          <div class="pl-4 text-xs text-base-content/60">
            ç‚¹å‡»å½•åˆ¶æŒ‰é’®æ—¶ä¼šè¯·æ±‚éº¦å…‹é£æƒé™ï¼Œè¯·å…è®¸è®¿é—®
          </div>
        </div>
      </div>

      <!-- å½•åˆ¶çŠ¶æ€æ˜¾ç¤º -->
      <div class="mb-4">
        <div class="flex items-center justify-between text-sm text-base-content/70 mb-2">
          <span>çŠ¶æ€: {{ recordingStatusText }}</span>
          <span v-if="isRecording || isPaused">{{ formatTime(recordingTime) }}</span>
        </div>
        
        <!-- è¿›åº¦æ¡ -->
        <div class="w-full bg-base-300 rounded-full h-2">
          <div class="bg-primary h-2 rounded-full transition-all duration-300" 
               :style="{ width: `${Math.min(recordingTime / maxRecordingTime * 100, 100)}%` }">
          </div>
        </div>
      </div>

      <!-- æ³¢å½¢æ˜¾ç¤ºåŒºåŸŸ -->
      <div class="mb-4">
        <canvas ref="waveformCanvas" 
                class="w-full h-16 bg-base-200 rounded border"
                :class="{ 'animate-pulse': isRecording }">
        </canvas>
      </div>

      <!-- å®æ—¶è½¬å½•æ˜¾ç¤º -->
      <div v-if="enableRealTimeTranscription && (isRecording || isPaused)" class="mb-4">
        <div class="text-sm font-medium mb-2 flex items-center gap-2">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 text-primary" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
              d="M7 4V2a1 1 0 011-1h8a1 1 0 011 1v2M7 4h10M7 4l-2 16h14L17 4M11 9v4m4-4v4" />
          </svg>
          å®æ—¶è½¬å½•
          <span v-if="isTranscribing" class="loading loading-spinner loading-xs"></span>
        </div>
        <div class="p-3 bg-base-200 rounded text-sm max-h-24 overflow-y-auto border"
             :class="{ 'opacity-50': !realtimeTranscriptionText.trim() }">
          <span v-if="realtimeTranscriptionText.trim()">{{ realtimeTranscriptionText }}</span>
          <span v-else class="text-base-content/50 italic">å¼€å§‹è¯´è¯ï¼Œè½¬å½•æ–‡æœ¬å°†åœ¨è¿™é‡Œæ˜¾ç¤º...</span>
          <span v-if="isTranscribing" class="inline-block w-2 h-4 bg-primary animate-pulse ml-1"></span>
        </div>
      </div>

      <!-- å½•åˆ¶æ§åˆ¶æŒ‰é’® -->
      <div class="flex justify-center gap-2 mb-4">
        <!-- å¼€å§‹/æš‚åœå½•åˆ¶ -->
        <button v-if="!isRecording && !isPaused" 
                @click="startRecording"
                :disabled="isLoading || deviceState !== 'available' || permissionState === 'denied'"
                class="btn btn-primary btn-circle"
                :class="{ 
                  'btn-disabled': deviceState !== 'available' || permissionState === 'denied',
                  'tooltip': deviceState !== 'available' || permissionState === 'denied' 
                }"
                :data-tip="deviceState !== 'available' ? 'éº¦å…‹é£è®¾å¤‡ä¸å¯ç”¨' : permissionState === 'denied' ? 'éº¦å…‹é£æƒé™è¢«æ‹’ç»' : ''">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
              d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
          </svg>
        </button>

        <!-- æš‚åœæŒ‰é’® -->
        <button v-if="isRecording" 
                @click="pauseRecording"
                class="btn btn-warning btn-circle">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 9v6m4-6v6" />
          </svg>
        </button>

        <!-- ç»§ç»­å½•åˆ¶æŒ‰é’® -->
        <button v-if="isPaused" 
                @click="resumeRecording"
                class="btn btn-success btn-circle">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14.828 14.828a4 4 0 01-5.656 0M9 10h1m4 0h1" />
          </svg>
        </button>

        <!-- åœæ­¢å½•åˆ¶ -->
        <button v-if="isRecording || isPaused" 
                @click="stopRecording"
                class="btn btn-error btn-circle">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 10h6v4H9V10z" />
          </svg>
        </button>

        <!-- é‡æ–°å½•åˆ¶ -->
        <button v-if="hasRecordedAudio && !isRecording && !isPaused" 
                @click="resetRecording"
                class="btn btn-ghost btn-circle"
                title="é‡æ–°å½•åˆ¶">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15" />
          </svg>
        </button>
      </div>

      <!-- éŸ³é¢‘é¢„è§ˆå’Œæ“ä½œ -->
      <div v-if="hasRecordedAudio" class="space-y-3">
        <!-- éŸ³é¢‘æ’­æ”¾å™¨ -->
        <div class="bg-base-200 rounded p-3">
          <div class="flex items-center gap-2 mb-2">
            <button @click="togglePlayback" class="btn btn-sm btn-ghost btn-circle">
              <svg v-if="!isPlaying" xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14.828 14.828a4 4 0 01-5.656 0M9 10h1m4 0h1" />
              </svg>
              <svg v-else xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 9v6m4-6v6" />
              </svg>
            </button>
            <div class="flex-1">
              <input type="range" 
                     v-model="playbackProgress"
                     @input="seekAudio"
                     min="0" 
                     max="100" 
                     class="range range-primary range-xs" />
            </div>
            <span class="text-xs text-base-content/70">{{ formatTime(audioDuration) }}</span>
          </div>
        </div>

        <!-- è½¬å½•é€‰é¡¹ -->
        <div class="space-y-2">
          <div class="flex items-center gap-2">
            <input type="checkbox" v-model="enableTranscription" class="checkbox checkbox-primary checkbox-sm" />
            <label class="text-sm">å¯ç”¨è¯­éŸ³è½¬æ–‡å­—</label>
          </div>
          
          <div v-if="enableTranscription" class="space-y-2">
            <div>
              <label class="block text-xs text-base-content/70 mb-1">è¯†åˆ«è¯­è¨€</label>
              <select v-model="transcriptionLanguage" class="select select-bordered select-sm w-full">
                <option value="auto">è‡ªåŠ¨æ£€æµ‹</option>
                <option value="zh">ä¸­æ–‡ (ç®€ä½“)</option>
                <option value="zh-TW">ä¸­æ–‡ (ç¹ä½“)</option>
                <option value="en">English</option>
                <option value="ja">æ—¥æœ¬èª</option>
                <option value="ko">í•œêµ­ì–´</option>
                <option value="es">EspaÃ±ol</option>
                <option value="fr">FranÃ§ais</option>
                <option value="de">Deutsch</option>
                <option value="it">Italiano</option>
                <option value="pt">PortuguÃªs</option>
                <option value="ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</option>
                <option value="ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</option>
                <option value="hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</option>
                <option value="th">à¹„à¸—à¸¢</option>
                <option value="vi">Tiáº¿ng Viá»‡t</option>
              </select>
            </div>
            
            <div>
              <label class="block text-xs text-base-content/70 mb-1">è¯†åˆ«æœåŠ¡</label>
              <select v-model="transcriptionService" class="select select-bordered select-sm w-full">
                <option value="openai">OpenAI Whisper (æ¨è)</option>
                <option value="azure">Azure Speech Services</option>
                <option value="google">Google Speech-to-Text</option>
                <option value="local">æœ¬åœ° Whisper æ¨¡å‹</option>
              </select>
            </div>
            
            <div v-if="transcriptionService === 'local'" class="alert alert-info py-2">
              <svg xmlns="http://www.w3.org/2000/svg" class="stroke-current shrink-0 h-4 w-4" fill="none" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
              </svg>
              <span class="text-xs">éœ€è¦å®‰è£… whisper CLI å·¥å…·</span>
            </div>
            
            <div class="flex items-center gap-2">
              <input type="checkbox" v-model="enableRealTimeTranscription" class="checkbox checkbox-primary checkbox-sm" />
              <label class="text-sm">å®æ—¶è½¬å½•æ˜¾ç¤º</label>
            </div>
            
            <div class="flex items-center gap-2">
              <input type="checkbox" v-model="enableAIAnalysis" class="checkbox checkbox-primary checkbox-sm" />
              <label class="text-sm">å¯ç”¨AIæ™ºèƒ½åˆ†æ</label>
            </div>
            
            <div v-if="enableAIAnalysis" class="space-y-2 pl-6">
              <div class="flex flex-wrap gap-2">
                <label class="flex items-center gap-1 text-xs">
                  <input type="checkbox" v-model="aiAnalysisOptions.generateTitle" class="checkbox checkbox-xs" />
                  æ™ºèƒ½æ ‡é¢˜
                </label>
                <label class="flex items-center gap-1 text-xs">
                  <input type="checkbox" v-model="aiAnalysisOptions.extractTags" class="checkbox checkbox-xs" />
                  è‡ªåŠ¨æ ‡ç­¾
                </label>
                <label class="flex items-center gap-1 text-xs">
                  <input type="checkbox" v-model="aiAnalysisOptions.generateSummary" class="checkbox checkbox-xs" />
                  å†…å®¹æ€»ç»“
                </label>
                <label class="flex items-center gap-1 text-xs">
                  <input type="checkbox" v-model="aiAnalysisOptions.extractKeywords" class="checkbox checkbox-xs" />
                  å…³é”®è¯æå–
                </label>
                <label class="flex items-center gap-1 text-xs">
                  <input type="checkbox" v-model="aiAnalysisOptions.sentimentAnalysis" class="checkbox checkbox-xs" />
                  æƒ…æ„Ÿåˆ†æ
                </label>
              </div>
            </div>
          </div>
        </div>

        <!-- æ“ä½œæŒ‰é’® -->
        <div class="flex gap-2">
          <button @click="insertAudioToNote" 
                  :disabled="isLoading"
                  class="btn btn-primary btn-sm flex-1">
            <span v-if="isLoading" class="loading loading-spinner loading-xs"></span>
            æ’å…¥åˆ°ç¬”è®°
          </button>
          <button @click="saveAudioFile" 
                  :disabled="isLoading"
                  class="btn btn-ghost btn-sm">
            ä¿å­˜æ–‡ä»¶
          </button>
        </div>
      </div>

      <!-- åŠ è½½çŠ¶æ€ -->
      <div v-if="isLoading" class="text-center py-4">
        <span class="loading loading-spinner loading-md"></span>
        <p class="text-sm text-base-content/70 mt-2">{{ loadingMessage }}</p>
      </div>
    </div>

    <!-- éšè—çš„éŸ³é¢‘å…ƒç´  -->
    <audio ref="audioPlayer" @loadedmetadata="onAudioLoaded" @timeupdate="onTimeUpdate"></audio>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onMounted, onBeforeUnmount, nextTick } from 'vue'
import { invoke } from '@tauri-apps/api/core'

// Props
const props = defineProps<{
  visible: boolean
  noteId?: string
}>()

// Emits
const emit = defineEmits<{
  close: []
  audioInserted: [audioId: string, transcription?: string, aiAnalysis?: any]
}>()

// å½•åˆ¶çŠ¶æ€
const isRecording = ref(false)
const isPaused = ref(false)
const isLoading = ref(false)
const loadingMessage = ref('')
const hasRecordedAudio = ref(false)
const recordingTime = ref(0)
const maxRecordingTime = ref(600) // 10åˆ†é’Ÿé™åˆ¶

// éŸ³é¢‘ç›¸å…³
const audioBlob = ref<Blob | null>(null)
const audioUrl = ref<string | null>(null)
const isPlaying = ref(false)
const playbackProgress = ref(0)
const audioDuration = ref(0)

// æƒé™çŠ¶æ€
const permissionState = ref<'granted' | 'denied' | 'prompt' | 'unknown'>('unknown')
const deviceState = ref<'available' | 'unavailable' | 'checking'>('checking')

// è½¬å½•è®¾ç½®
const enableTranscription = ref(true)
const transcriptionLanguage = ref('zh')
const transcriptionService = ref('openai')

// AIåˆ†æè®¾ç½®
const enableAIAnalysis = ref(false)
const aiAnalysisOptions = ref({
  generateTitle: true,
  extractTags: true,
  generateSummary: false,
  extractKeywords: false,
  sentimentAnalysis: false
})

// å®æ—¶è½¬å½•è®¾ç½®
const enableRealTimeTranscription = ref(false)
const isTranscribing = ref(false)
const realtimeTranscriptionText = ref('')

// DOM å¼•ç”¨
const waveformCanvas = ref<HTMLCanvasElement | null>(null)
const audioPlayer = ref<HTMLAudioElement | null>(null)

// MediaRecorder ç›¸å…³
let mediaRecorder: MediaRecorder | null = null
let audioContext: AudioContext | null = null
let analyser: AnalyserNode | null = null
let microphone: MediaStreamAudioSourceNode | null = null
let recordingTimer: ReturnType<typeof setInterval> | null = null
let animationId: number | null = null

// éŸ³é¢‘æ•°æ®
const audioChunks: Blob[] = []

// è®¡ç®—å±æ€§
const showRecordingPanel = computed(() => props.visible)

const recordingStatusText = computed(() => {
  if (isLoading.value) return 'å¤„ç†ä¸­...'
  if (isRecording.value) return 'å½•åˆ¶ä¸­'
  if (isPaused.value) return 'å·²æš‚åœ'
  if (hasRecordedAudio.value) return 'å½•åˆ¶å®Œæˆ'
  return 'å‡†å¤‡å½•åˆ¶'
})

// æ–¹æ³•
const closePanel = () => {
  stopRecording()
  emit('close')
}

// æ£€æŸ¥æƒé™çŠ¶æ€
const checkPermissionStatus = async () => {
  if (!navigator.permissions || !navigator.permissions.query) {
    return 'unknown'
  }
  
  try {
    const result = await navigator.permissions.query({ name: 'microphone' as PermissionName })
    return result.state
  } catch (error) {
    console.warn('æ— æ³•æŸ¥è¯¢éº¦å…‹é£æƒé™çŠ¶æ€:', error)
    return 'unknown'
  }
}

// æ£€æŸ¥éŸ³é¢‘è®¾å¤‡å¯ç”¨æ€§
const checkAudioDeviceAvailability = async () => {
  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
    return false
  }
  
  try {
    // é¦–å…ˆå°è¯•ä¸å¸¦æƒé™çš„è®¾å¤‡æšä¸¾
    let devices = await navigator.mediaDevices.enumerateDevices()
    let hasAudioInput = devices.some(device => device.kind === 'audioinput')
    
    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘è¾“å…¥è®¾å¤‡ï¼Œå¯èƒ½æ˜¯æƒé™é—®é¢˜
    // å°è¯•è¯·æ±‚ä¸´æ—¶æƒé™æ¥è·å–æ›´å‡†ç¡®çš„è®¾å¤‡ä¿¡æ¯
    if (!hasAudioInput) {
      try {
        const tempStream = await navigator.mediaDevices.getUserMedia({ 
          audio: true 
        })
        
        // ç«‹å³åœæ­¢æµï¼Œæˆ‘ä»¬åªæ˜¯ä¸ºäº†è§¦å‘æƒé™è¯·æ±‚
        tempStream.getTracks().forEach(track => track.stop())
        
        // é‡æ–°æšä¸¾è®¾å¤‡
        devices = await navigator.mediaDevices.enumerateDevices()
        hasAudioInput = devices.some(device => device.kind === 'audioinput')
        
        // æ›´æ–°æƒé™çŠ¶æ€
        permissionState.value = 'granted'
        
      } catch (permError: any) {
        console.warn('æ— æ³•è·å–éº¦å…‹é£æƒé™è¿›è¡Œè®¾å¤‡æ£€æµ‹:', permError)
        
        // æ ¹æ®é”™è¯¯ç±»å‹æ›´æ–°æƒé™çŠ¶æ€
        if (permError.name === 'NotAllowedError') {
          permissionState.value = 'denied'
        } else if (permError.name === 'NotFoundError') {
          // ç¡®å®æ²¡æœ‰è®¾å¤‡
          return false
        }
        
        // å¯¹äºå…¶ä»–é”™è¯¯ï¼Œå‡è®¾è®¾å¤‡å­˜åœ¨ä½†éœ€è¦æƒé™
        return true
      }
    }
    
    return hasAudioInput
  } catch (error) {
    console.warn('æ— æ³•æšä¸¾éŸ³é¢‘è®¾å¤‡:', error)
    // è®¾å¤‡æšä¸¾å¤±è´¥ï¼Œä½†ä¸ä»£è¡¨æ²¡æœ‰è®¾å¤‡ï¼Œå¯èƒ½æ˜¯æƒé™æˆ–APIé—®é¢˜
    return true
  }
}

// æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒéŸ³é¢‘å½•åˆ¶
const checkAudioRecordingSupport = () => {
  const errors = []
  
  // æ£€æŸ¥ navigator.mediaDevices æ˜¯å¦å¯ç”¨
  if (!navigator.mediaDevices) {
    errors.push('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒ MediaDevices API')
  }
  
  // æ£€æŸ¥ getUserMedia æ˜¯å¦å¯ç”¨
  if (!navigator.mediaDevices?.getUserMedia) {
    errors.push('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéº¦å…‹é£è®¿é—®åŠŸèƒ½')
  }
  
  // æ£€æŸ¥ MediaRecorder æ˜¯å¦å¯ç”¨
  if (!window.MediaRecorder) {
    errors.push('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å½•åˆ¶åŠŸèƒ½')
  }
  
  // æ£€æŸ¥æ˜¯å¦åœ¨å®‰å…¨ä¸Šä¸‹æ–‡ä¸­è¿è¡Œï¼ˆHTTPS æˆ– localhostï¼‰
  if (location.protocol !== 'https:' && 
      !location.hostname.includes('localhost') && 
      location.hostname !== '127.0.0.1' &&
      location.protocol !== 'tauri:') {
    errors.push('éŸ³é¢‘å½•åˆ¶éœ€è¦åœ¨å®‰å…¨ç¯å¢ƒä¸‹è¿è¡Œï¼ˆHTTPSï¼‰')
  }
  
  return {
    supported: errors.length === 0,
    errors
  }
}

// åˆå§‹åŒ–éŸ³é¢‘ç¯å¢ƒæ£€æŸ¥
const initializeAudioEnvironment = async () => {
  try {
    deviceState.value = 'checking'
    
    // æ£€æŸ¥æƒé™çŠ¶æ€
    permissionState.value = await checkPermissionStatus()
    
    // æ£€æŸ¥è®¾å¤‡å¯ç”¨æ€§
    const hasAudioDevices = await checkAudioDeviceAvailability()
    deviceState.value = hasAudioDevices ? 'available' : 'unavailable'
    
    console.log(`éŸ³é¢‘ç¯å¢ƒçŠ¶æ€ - æƒé™: ${permissionState.value}, è®¾å¤‡: ${deviceState.value}`)
  } catch (error) {
    console.error('åˆå§‹åŒ–éŸ³é¢‘ç¯å¢ƒæ£€æŸ¥å¤±è´¥:', error)
    deviceState.value = 'unavailable'
  }
}

// æµ‹è¯•éº¦å…‹é£åŠŸèƒ½
const testMicrophone = async () => {
  try {
    deviceState.value = 'checking'
    
    // ç›´æ¥å°è¯•è·å–éº¦å…‹é£è®¿é—®æƒé™
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    })
    
    // ç«‹å³åœæ­¢æµ
    stream.getTracks().forEach(track => track.stop())
    
    // æ›´æ–°çŠ¶æ€
    permissionState.value = 'granted'
    deviceState.value = 'available'
    
    // æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
    const successDiv = document.createElement('div')
    successDiv.className = 'toast toast-top toast-center z-[9999]'
    successDiv.innerHTML = `
      <div class="alert alert-success">
        <svg xmlns="http://www.w3.org/2000/svg" class="stroke-current shrink-0 h-6 w-6" fill="none" viewBox="0 0 24 24">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z" />
        </svg>
        <span>âœ… éº¦å…‹é£æµ‹è¯•æˆåŠŸï¼è®¾å¤‡å·¥ä½œæ­£å¸¸ï¼Œæƒé™å·²æˆæƒã€‚</span>
      </div>
    `
    
    document.body.appendChild(successDiv)
    
    setTimeout(() => {
      if (successDiv.parentNode) {
        successDiv.parentNode.removeChild(successDiv)
      }
    }, 3000)
    
    // é‡æ–°åˆå§‹åŒ–ç¯å¢ƒæ£€æŸ¥
    setTimeout(() => {
      initializeAudioEnvironment()
    }, 1000)
    
  } catch (error: any) {
    let errorMessage = 'éº¦å…‹é£æµ‹è¯•å¤±è´¥ï¼š'
    
    switch (error.name) {
      case 'NotAllowedError':
        errorMessage += 'ç”¨æˆ·æ‹’ç»äº†éº¦å…‹é£æƒé™è¯·æ±‚'
        permissionState.value = 'denied'
        deviceState.value = 'unavailable'
        break
      case 'NotFoundError':
        errorMessage += 'æœªæ‰¾åˆ°å¯ç”¨çš„éº¦å…‹é£è®¾å¤‡'
        permissionState.value = 'unknown'
        deviceState.value = 'unavailable'
        break
      case 'NotReadableError':
        errorMessage += 'éº¦å…‹é£è®¾å¤‡è¢«å…¶ä»–åº”ç”¨å ç”¨'
        permissionState.value = 'unknown'
        deviceState.value = 'unavailable'
        break
      case 'OverconstrainedError':
        errorMessage += 'éº¦å…‹é£è®¾å¤‡ä¸æ”¯æŒæŒ‡å®šçš„é…ç½®'
        permissionState.value = 'unknown'
        deviceState.value = 'unavailable'
        break
      case 'SecurityError':
        errorMessage += 'å®‰å…¨é™åˆ¶é˜»æ­¢è®¿é—®éº¦å…‹é£'
        permissionState.value = 'denied'
        deviceState.value = 'unavailable'
        break
      default:
        errorMessage += error.message || 'æœªçŸ¥é”™è¯¯'
        deviceState.value = 'unavailable'
    }
    
    showErrorMessage(errorMessage)
    console.error('Microphone test failed:', error)
  }
}

// æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
const showErrorMessage = (message: string) => {
  // åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„é”™è¯¯æç¤ºå…ƒç´ 
  const errorDiv = document.createElement('div')
  errorDiv.className = 'toast toast-top toast-center z-[9999]'
  errorDiv.innerHTML = `
    <div class="alert alert-error">
      <svg xmlns="http://www.w3.org/2000/svg" class="stroke-current shrink-0 h-6 w-6" fill="none" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 14l2-2m0 0l2-2m-2 2l-2-2m2 2l2 2m7-2a9 9 0 11-18 0 9 9 0 0118 0z" />
      </svg>
      <span>${message}</span>
    </div>
  `
  
  document.body.appendChild(errorDiv)
  
  // 3ç§’åç§»é™¤æç¤º
  setTimeout(() => {
    if (errorDiv.parentNode) {
      errorDiv.parentNode.removeChild(errorDiv)
    }
  }, 5000)
}

const startRecording = async () => {
  try {
    isLoading.value = true
    loadingMessage.value = 'æ£€æŸ¥éŸ³é¢‘å½•åˆ¶æ”¯æŒ...'

    // é¦–å…ˆæ£€æŸ¥æµè§ˆå™¨æ”¯æŒæƒ…å†µ
    const supportCheck = checkAudioRecordingSupport()
    if (!supportCheck.supported) {
      const errorMessage = 'éŸ³é¢‘å½•åˆ¶ä¸å¯ç”¨ï¼š\n' + supportCheck.errors.join('\n')
      showErrorMessage(errorMessage)
      console.error('Audio recording not supported:', supportCheck.errors)
      return
    }

    loadingMessage.value = 'è¯·æ±‚éº¦å…‹é£æƒé™...'

    // å°è¯•è·å–éº¦å…‹é£æƒé™
    let stream: MediaStream
    try {
      stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100
        }
      })
    } catch (mediaError: any) {
      let errorMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£ï¼š'
      
      switch (mediaError.name) {
        case 'NotAllowedError':
          errorMessage += 'ç”¨æˆ·æ‹’ç»äº†éº¦å…‹é£æƒé™è¯·æ±‚'
          break
        case 'NotFoundError':
          errorMessage += 'æœªæ‰¾åˆ°å¯ç”¨çš„éº¦å…‹é£è®¾å¤‡'
          break
        case 'NotReadableError':
          errorMessage += 'éº¦å…‹é£è®¾å¤‡è¢«å…¶ä»–åº”ç”¨å ç”¨'
          break
        case 'OverconstrainedError':
          errorMessage += 'éº¦å…‹é£è®¾å¤‡ä¸æ”¯æŒæŒ‡å®šçš„é…ç½®'
          break
        case 'SecurityError':
          errorMessage += 'å®‰å…¨é™åˆ¶é˜»æ­¢è®¿é—®éº¦å…‹é£'
          break
        default:
          errorMessage += mediaError.message || 'æœªçŸ¥é”™è¯¯'
      }
      
      showErrorMessage(errorMessage)
      console.error('Media access error:', mediaError)
      return
    }

    // è®¾ç½®éŸ³é¢‘åˆ†æ
    await setupAudioAnalysis(stream)

    // åˆ›å»º MediaRecorder
    const options = {
      mimeType: 'audio/webm;codecs=opus',
      audioBitsPerSecond: 128000
    }

    if (!MediaRecorder.isTypeSupported(options.mimeType)) {
      options.mimeType = 'audio/webm'
      if (!MediaRecorder.isTypeSupported(options.mimeType)) {
        // å°è¯•å…¶ä»–æ ¼å¼
        const fallbackTypes = ['audio/mp4', 'audio/ogg', 'audio/wav']
        let supportedType = null
        
        for (const type of fallbackTypes) {
          if (MediaRecorder.isTypeSupported(type)) {
            supportedType = type
            break
          }
        }
        
        if (supportedType) {
          options.mimeType = supportedType
        } else {
          showErrorMessage('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒä»»ä½•å¯ç”¨çš„éŸ³é¢‘å½•åˆ¶æ ¼å¼')
          stream.getTracks().forEach(track => track.stop())
          return
        }
      }
    }

    mediaRecorder = new MediaRecorder(stream, options)

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.push(event.data)
      }
    }

    mediaRecorder.onstop = () => {
      audioBlob.value = new Blob(audioChunks, { type: 'audio/webm' })
      audioUrl.value = URL.createObjectURL(audioBlob.value)
      hasRecordedAudio.value = true
      
      if (audioPlayer.value) {
        audioPlayer.value.src = audioUrl.value
      }
    }

    // å¼€å§‹å½•åˆ¶
    mediaRecorder.start(1000) // æ¯ç§’æ”¶é›†æ•°æ®
    isRecording.value = true
    recordingTime.value = 0

    // å¯åŠ¨è®¡æ—¶å™¨
    startTimer()
    startWaveformVisualization()
    
    // å¯åŠ¨å®æ—¶è½¬å½•æ¨¡æ‹Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if (enableRealTimeTranscription.value) {
      startRealtimeTranscription()
    }

    isLoading.value = false
  } catch (error: any) {
    console.error('Failed to start recording:', error)
    showErrorMessage(`å½•åˆ¶å¯åŠ¨å¤±è´¥ï¼š${error.message || 'æœªçŸ¥é”™è¯¯'}`)
    isLoading.value = false
  }
}

const pauseRecording = () => {
  if (mediaRecorder && mediaRecorder.state === 'recording') {
    mediaRecorder.pause()
    isRecording.value = false
    isPaused.value = true
    stopTimer()
    if (enableRealTimeTranscription.value) {
      isTranscribing.value = false
      realtimeTranscriptionText.value = 'å½•åˆ¶å·²æš‚åœ...'
    }
  }
}

const resumeRecording = () => {
  if (mediaRecorder && mediaRecorder.state === 'paused') {
    mediaRecorder.resume()
    isRecording.value = true
    isPaused.value = false
    startTimer()
    if (enableRealTimeTranscription.value) {
      startRealtimeTranscription()
    }
  }
}

const stopRecording = () => {
  if (mediaRecorder && (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused')) {
    mediaRecorder.stop()
    
    // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
    if (mediaRecorder.stream) {
      mediaRecorder.stream.getTracks().forEach(track => track.stop())
    }
  }

  isRecording.value = false
  isPaused.value = false
  stopTimer()
  stopWaveformVisualization()
  stopRealtimeTranscription()
}

const resetRecording = () => {
  // æ¸…ç†éŸ³é¢‘æ•°æ®
  audioChunks.length = 0
  audioBlob.value = null
  if (audioUrl.value) {
    URL.revokeObjectURL(audioUrl.value)
    audioUrl.value = null
  }
  
  hasRecordedAudio.value = false
  recordingTime.value = 0
  playbackProgress.value = 0
  audioDuration.value = 0
  isPlaying.value = false

  if (audioPlayer.value) {
    audioPlayer.value.src = ''
  }
}

const setupAudioAnalysis = async (stream: MediaStream) => {
  audioContext = new AudioContext()
  analyser = audioContext.createAnalyser()
  microphone = audioContext.createMediaStreamSource(stream)
  
  analyser.fftSize = 512
  analyser.smoothingTimeConstant = 0.8
  
  microphone.connect(analyser)
}

const startWaveformVisualization = () => {
  if (!analyser || !waveformCanvas.value) return

  const canvas = waveformCanvas.value
  const ctx = canvas.getContext('2d')
  if (!ctx) return

  const bufferLength = analyser.frequencyBinCount
  const dataArray = new Uint8Array(bufferLength)

  const draw = () => {
    if (!isRecording.value || !analyser) return

    animationId = requestAnimationFrame(draw)
    
    analyser.getByteFrequencyData(dataArray)

    ctx.fillStyle = 'rgb(30, 30, 30)'
    ctx.fillRect(0, 0, canvas.width, canvas.height)

    const barWidth = canvas.width / bufferLength
    let x = 0

    for (let i = 0; i < bufferLength; i++) {
      const barHeight = (dataArray[i] / 255) * canvas.height * 0.8
      
      const r = barHeight + 25
      const g = 250 * (i / bufferLength)
      const b = 50

      ctx.fillStyle = `rgb(${r},${g},${b})`
      ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight)

      x += barWidth + 1
    }
  }

  draw()
}

const stopWaveformVisualization = () => {
  if (animationId) {
    cancelAnimationFrame(animationId)
    animationId = null
  }
}

const startTimer = () => {
  recordingTimer = setInterval(() => {
    recordingTime.value += 1
    if (recordingTime.value >= maxRecordingTime.value) {
      stopRecording()
    }
  }, 1000)
}

const stopTimer = () => {
  if (recordingTimer) {
    clearInterval(recordingTimer)
    recordingTimer = null
  }
}

const togglePlayback = () => {
  if (!audioPlayer.value) return

  if (isPlaying.value) {
    audioPlayer.value.pause()
  } else {
    audioPlayer.value.play()
  }
}

const seekAudio = () => {
  if (!audioPlayer.value) return
  
  const seekTime = (playbackProgress.value / 100) * audioDuration.value
  audioPlayer.value.currentTime = seekTime
}

const onAudioLoaded = () => {
  if (audioPlayer.value) {
    audioDuration.value = audioPlayer.value.duration
  }
}

const onTimeUpdate = () => {
  if (audioPlayer.value && audioDuration.value > 0) {
    playbackProgress.value = (audioPlayer.value.currentTime / audioDuration.value) * 100
  }
}

const insertAudioToNote = async () => {
  if (!audioBlob.value || !props.noteId) return

  try {
    isLoading.value = true
    loadingMessage.value = 'ä¿å­˜éŸ³é¢‘æ–‡ä»¶...'

    // è½¬æ¢éŸ³é¢‘ä¸º base64
    const arrayBuffer = await audioBlob.value.arrayBuffer()
    const uint8Array = new Uint8Array(arrayBuffer)
    const base64Audio = btoa(String.fromCharCode(...uint8Array))

    // ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    const audioId = await invoke<string>('save_audio_file', {
      audioData: {
        tip_id: props.noteId,
        audio_data: base64Audio,
        file_format: 'webm',
        duration: Math.round(audioDuration.value * 1000)
      }
    })

    let transcription = ''
    let aiAnalysisResult = null
    
    // å¦‚æœå¯ç”¨è½¬å½•ï¼Œæ‰§è¡Œè¯­éŸ³è½¬æ–‡å­—
    if (enableTranscription.value) {
      loadingMessage.value = 'è½¬å½•éŸ³é¢‘å†…å®¹...'
      
      transcription = await invoke<string>('transcribe_audio', {
        audioId,
        language: transcriptionLanguage.value === 'auto' ? null : transcriptionLanguage.value,
        service: transcriptionService.value
      })
      
      // å¦‚æœå¯ç”¨AIåˆ†æï¼Œæ‰§è¡Œå†…å®¹åˆ†æ
      if (enableAIAnalysis.value && transcription.trim()) {
        loadingMessage.value = 'åˆ†æéŸ³é¢‘å†…å®¹...'
        
        const analysisTypes = []
        if (aiAnalysisOptions.value.generateTitle) analysisTypes.push('title')
        if (aiAnalysisOptions.value.extractTags) analysisTypes.push('tags')
        if (aiAnalysisOptions.value.generateSummary) analysisTypes.push('summary')
        if (aiAnalysisOptions.value.extractKeywords) analysisTypes.push('keywords')
        if (aiAnalysisOptions.value.sentimentAnalysis) analysisTypes.push('sentiment')
        
        if (analysisTypes.length > 0) {
          try {
            aiAnalysisResult = await invoke('analyze_audio_content', {
              audioId,
              transcriptionText: transcription,
              analysisTypes,
              language: transcriptionLanguage.value === 'auto' ? null : transcriptionLanguage.value
            })
          } catch (error) {
            console.warn('AI analysis failed:', error)
          }
        }
      }
    }

    emit('audioInserted', audioId, transcription, aiAnalysisResult)
    resetRecording()
    closePanel()

  } catch (error) {
    console.error('Failed to insert audio:', error)
    // TODO: æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
  } finally {
    isLoading.value = false
  }
}

const saveAudioFile = async () => {
  if (!audioBlob.value) return

  try {
    // åˆ›å»ºä¸‹è½½é“¾æ¥
    const url = URL.createObjectURL(audioBlob.value)
    const a = document.createElement('a')
    a.href = url
    a.download = `recording_${new Date().toISOString().replace(/[:.]/g, '-')}.webm`
    document.body.appendChild(a)
    a.click()
    document.body.removeChild(a)
    URL.revokeObjectURL(url)
  } catch (error) {
    console.error('Failed to save audio file:', error)
  }
}

const formatTime = (seconds: number): string => {
  const mins = Math.floor(seconds / 60)
  const secs = seconds % 60
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
}

// å®æ—¶è½¬å½•ç›¸å…³å‡½æ•°
let realtimeTranscriptionTimer: ReturnType<typeof setInterval> | null = null

const startRealtimeTranscription = () => {
  if (!enableRealTimeTranscription.value) return
  
  realtimeTranscriptionText.value = ''
  isTranscribing.value = true
  
  // æ¨¡æ‹Ÿå®æ—¶è½¬å½•è¿‡ç¨‹
  const mockTranscriptionSegments = [
    'æ­£åœ¨ç›‘å¬...',
    'æ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥',
    'å¼€å§‹è¯†åˆ«è¯­éŸ³å†…å®¹',
    'è½¬å½•ä¸­...',
    'å¤„ç†è¯­éŸ³ä¿¡å·',
    'ç”Ÿæˆæ–‡æœ¬...'
  ]
  
  let segmentIndex = 0
  
  realtimeTranscriptionTimer = setInterval(() => {
    if (segmentIndex < mockTranscriptionSegments.length) {
      realtimeTranscriptionText.value = mockTranscriptionSegments[segmentIndex]
      segmentIndex++
    } else {
      // å¾ªç¯æ˜¾ç¤ºæç¤º
      segmentIndex = 0
    }
  }, 2000)
}

const stopRealtimeTranscription = () => {
  if (realtimeTranscriptionTimer) {
    clearInterval(realtimeTranscriptionTimer)
    realtimeTranscriptionTimer = null
  }
  isTranscribing.value = false
  realtimeTranscriptionText.value = ''
}

// ç”Ÿå‘½å‘¨æœŸ
onMounted(() => {
  // è®¾ç½®canvaså°ºå¯¸
  nextTick(() => {
    if (waveformCanvas.value) {
      const canvas = waveformCanvas.value
      canvas.width = canvas.offsetWidth
      canvas.height = canvas.offsetHeight
    }
  })

  // ç›‘å¬éŸ³é¢‘æ’­æ”¾äº‹ä»¶
  if (audioPlayer.value) {
    audioPlayer.value.addEventListener('play', () => { isPlaying.value = true })
    audioPlayer.value.addEventListener('pause', () => { isPlaying.value = false })
    audioPlayer.value.addEventListener('ended', () => { 
      isPlaying.value = false
      playbackProgress.value = 0
    })
  }
  
  // åˆå§‹åŒ–éŸ³é¢‘ç¯å¢ƒæ£€æŸ¥
  initializeAudioEnvironment()
})

onBeforeUnmount(() => {
  stopRecording()
  stopWaveformVisualization()
  stopRealtimeTranscription()
  
  if (audioUrl.value) {
    URL.revokeObjectURL(audioUrl.value)
  }
  
  if (audioContext) {
    audioContext.close()
  }
})
</script>

<style scoped>
.recording-panel {
  backdrop-filter: blur(10px);
  animation: fadeInScale 0.2s ease-out;
}

@keyframes fadeInScale {
  from {
    opacity: 0;
    transform: scale(0.95);
  }
  to {
    opacity: 1;
    transform: scale(1);
  }
}

.range {
  height: 4px;
}

.range::-webkit-slider-thumb {
  height: 16px;
  width: 16px;
}

canvas {
  image-rendering: pixelated;
}

@media (max-width: 768px) {
  .recording-panel {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    width: 100%;
    height: 100%;
    border-radius: 0;
    z-index: 9999;
  }
}
</style> 